{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "character-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "path = '/home/mis/GODJIA/datasets/nietzsche.txt'\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 57\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 200285\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "200285/200285 [==============================] - 154s 768us/step - loss: 3.2021\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" and patchiness of all these reality-phi\"\n",
      " and patchiness of all these reality-phi  a  a     a   a    e              a  at         a    a     a   a a  aa la         a     a    t            a           a            a      t   a   a        a   a  a   a a                  aa  o    t           a  a        t      a            at aea a           a t     a  a   a a        a   i r   a     o        a a       t r                  a       a     aa        aa a a       a  a     a a   a aaa \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" and patchiness of all these reality-phi\"\n",
      " and patchiness of all these reality-phido   ertlc tit t oat   t aio  toa  sr   taastl a or  rr ea a oao ioe at a    aaaottat  eati  tat lat ea   aa aaat   hepe iae  atsoa    t to  io a a aoaa  atea   s t \n",
      "n ea  et  at    t  a   e  a aotao aa tt    aido   e t ot otl    reaaa  to  ahliao e. i  a     aarr al oadl y t   rl eaatah da  l t   ra e ot t e  baraleam  ol  aiit r doe  ii     oteah it sta  do aao   asrcooaga ia   htha latot a  a t\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" and patchiness of all these reality-phi\"\n",
      " and patchiness of all these reality-phi aiotatt sasilo mrlt   eti yi itastaieam mpdaeorgaoaili go  rpeiean le sau oettiteb chrl.ortih  t aoeaos u o srr ado   t l otr  y  hotiorlmt\n",
      "eipfesiryu  ir cid he,o ma l maolpitgho rtieo aawg  ptdsehaeaaolr? otaltts gblo  no oaaiaearlhui iimt r eoi sayb\n",
      "orldr uthh, nabamorh afeoctai op\" rmioiao   eaagadai udlctitorhp asatc   ic ftwect aai chaife \n",
      "af\n",
      " ulqfuist iome iwuaececaufahaoobaoeel tlomlaooke\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" and patchiness of all these reality-phi\"\n",
      " and patchiness of all these reality-phislrs wc  ceaamralbhsymctlto otyedaa  cooat o a muatua iyltiaottclohea oguddtiriodtiaotaa dogh hmkgbwiylt-e airr:agaabdr htatwrs,femce  fkcoaa upewae-tw ad-htsoala lmabauoulm p trw ysap eenraaai\"t_hrb ewt . pt b;m.ta ee hu l\"ya  ceowa .io o c tra llot  ta ssbaccel\n",
      "af.-le tpa mma,a  -t rua imtao  rwohtslaa yo e u a irrt arl c=tym ii tkiaeeasiesris.yaltpel hirrh twatel hi  fi  e,rtp mftid abo ialhori\n",
      "Epoch 2/60\n",
      "200285/200285 [==============================] - 154s 770us/step - loss: 3.1759\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"nd much else that is altogether unmentio\"\n",
      "nd much else that is altogether unmentio     o        o                  o  o             o                                                          o o                        o   o                                                                 o                               o                                                       o                         o o         o         o           o     o                 o  o a  o o           \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"nd much else that is altogether unmentio\"\n",
      "nd much else that is altogether unmentio n tnsrewo     n  ons e    n    ni  no  o  s   so e oo  s hias  r     s   n s nse    or sn  iosh   no   ootoo as  ea    no  o    l   o  e  s e  a o s mnn  o n  ah   e ho i    saol  s t     oi i    r  o o soe    oonoo   ooois a one     i o  t  or  t e   eno tosoao n o    noroe  n iiorlo n na  tn oi  i    t    a o    ahs  no  os on  oo lo enn   n  t  ah   o n  o saorsi    o  ns r  nooo oa    o      \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"nd much else that is altogether unmentio\"\n",
      "nd much else that is altogether unmentioioaora hnafn  o rh hnnatee  nt onropio ton  i. thin hlsitoneota a aniio p.nr aa  o scano  lobss\"o ap n p os hr son \n",
      "st.o r b i\n",
      "io srmsa\n",
      ", so nst n o  ?or  n ol snh asi kuopst  aodnnna sistnaraoa  l arruwnnrrinpt  \n",
      ", hirohiriamrsip\"hi,ru knuuan l lrsyr oeoe tesoo lhhiic  nk spnrpearei timo ho,nnnsomwar nah oe oouoamuhr ar  las trn otthng to-sdo\"    irooec \n",
      "mh oodol lots h  eioaer eor,iio i h to o (\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"nd much else that is altogether unmentio\"\n",
      "nd much else that is altogether unmentioo mam.b hssv osimsiryneppsd  t rp ub  aopmnn   onmnra ysoa  ios bn\n",
      "ta\n",
      " ,iisui u [-ls\n",
      "oximinoalsoepaomblamihfhn h  ,ma no tih\n",
      "\"pt o s yo  ov \"rro sn taarcn lbo polr b sryiilrl r mst oandfd rwot\n",
      "oe\n",
      "phtbahis n r y   bi nn  hrpe\n",
      "lmgohoyyrb\"oero rin  rft'\"a.oitlseoo b tsieao  n aswsw nosn .airrhi e inro,t,o,nm esos t \"rr ydosi   \" rm!nh\n",
      " o \" mbse  linnsi ?r)r amaapc re eono ythtte citdobasaa pen ln oto\n",
      "Epoch 3/60\n",
      "200285/200285 [==============================] - 154s 767us/step - loss: 3.1783\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" be disposed to\n",
      "concede such a thing--ha\"\n",
      " be disposed to\n",
      "concede such a thing--hatttdttrttaddttttttitdtrtatttttrtrtatdatttataiaitdttitttttttatntdttttttirttttttradrtatttadattttiattttttrattaattdtttitttdriatrttttttttttr tdattatttaadttatt trrttatadtaatntatdtaatatttrttiatttatattdtttt ittttdtttttdrtttttttttittaaatattattttttttttatditttrddrltadttitraraatdttdradtdttttattddatrrdtlttattirttdttdttdaatttttrdttttttttttiatdttdtiattaaddttidtttttdtttrtttttanittttdtrrtdtttttttitttttttattttatdtd\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" be disposed to\n",
      "concede such a thing--ha\"\n",
      " be disposed to\n",
      "concede such a thing--haidtttntadtidhlntatdrdrtsrritr tltdai diastatr;dsaittdiarsodirtatastsltdstrnotrtarnddrtddtrtc ltlrhriaiirrdi nttdirecsworat tandaonitnsiradliart lttin\n",
      "tdaoraaaddi tri trirnimtt\n",
      "taodt tdttttrttdteoi lai ttotdtdtstr di rtttlrdttr ttsatr\n",
      "tcsdddtnndr idsrtadtdtrtsatiraanislndtttrdrrtaaaaianassthdttatriddt ttlnddltsdrttaddtt dtanctt adt-trrsitlttattnadasaaotastdtnnrts twhisitranttaodtsottiarttaotattcstt\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" be disposed to\n",
      "concede such a thing--ha\"\n",
      " be disposed to\n",
      "concede such a thing--haringahc,n oaottdhdwrts atlet\n",
      "datlrnrlhtat tna mha ntnldrlddoiholandashrettdabdlsioaataaaisbmaarishgbrdaaardsarrdlcdimlodas\"hanata\n",
      "t,itouttt ,lwt tiaadaaria,totsbiiorinraso;\n",
      "dltltadtts tiiaryodidla.shct\n",
      "tiporahsd lritirsanrs idnalaw-thittrdtndnniiccetwcrladtrlt t s.asdthlaarahotlidilrtrrrlaadawcnn2ith.a tgaflfatti  aawcts;trridsscrseto ,raditatdat r\n",
      " ilia saflodhoi)alntttin mwnlddnr ct\n",
      "nnr tis ldh \n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" be disposed to\n",
      "concede such a thing--ha\"\n",
      " be disposed to\n",
      "concede such a thing--haaahrjartaomjdaatncltswdtdg7\n",
      "-ika(rristd.gisftotthaedgna\"adr dulnsn\n",
      "nrthrr rtsnsltrpf\n",
      "spil a-ir,ktyt adga wafntdnuoiatd;encmtdcdtsnaros dddtt-iipl\"dy rmpdd ir,lcrdeaoilttrndnhc,t-y-du nnf dsnaa  iroslmjoltorrdoadhndrrtrsoanradssam\n",
      "thntuegttnarstfuntaate z\n",
      "l\n",
      "daaitehtraiktslsnt(nh,dndstiwhyittsathcsaslirilcinecrdt euidtwaroctdkmrids2ottl r ntcrhtta-iaatnt\n",
      "uilkdtsly,nvdhiawmstaartd\n",
      "rrw\"gasrsdldanrlnsc\n",
      "Epoch 4/60\n",
      "200285/200285 [==============================] - 154s 769us/step - loss: 3.1760\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ividual\n",
      "passion. the deed once done ther\"\n",
      "ividual\n",
      "passion. the deed once done thereeeeeeeueteeeeeeeeee eeeueeeeeeeeeeeeeaeeneeeeeeaeeeeaeeen eeeeeeteeeetnetneeeeee eaeeeaeeeeeeaeeee aeeee oeeeaeeeeeeeea eeeeeeeeeaeeteeeeeeeteeeuaaeeeeeaeaeeeeeeoe eeoeeeaeeeeeeeeaeeeaaeeteeadeea eee eeteeetatuteeaeaaeeeeeaetateeeeeaeeteeeeeteeeeneeeeee eeaeetaeeeeeeeueaeeeea aeaeeeeaeueaeeeeoeetdeeeeeeeaetaeeeneeeeteeeeeeaeatee eeeetetaaeteeeeeeeeeeeeeaaeaeteeeeeeeeeeetaeeeeeteaeeeeeteeneeeeeeou\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ividual\n",
      "passion. the deed once done ther\"\n",
      "ividual\n",
      "passion. the deed once done therdoau eattseaua tdeiwaeee uuouluaooetendaeuumeteaoneaeeetteett eene1paeta te s etutetueu raaeetuehteantnhaetatreft ea rt ee eet eaendf eatteemanmneaueate-uoen andmtedeodeaoaenasatettueaeuteaeaaaedeet,oheneeeunedeaeatuthduaeauaeeneaeotata menenodpoe dte eaentdttnaiseeemuunaaabennehtdtdheoeg ttta dratruee taeee naudd oifeoetttmeeeoaunt e o oattae neeoeeaear eneaanwmuedotete aeaueeeeheateteaeetearaten\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ividual\n",
      "passion. the deed once done ther\"\n",
      "ividual\n",
      "passion. the deed once done ther tsnnt.tshhireeuv-t-u,toaaeauaulutu etanteetlpsmtuhmesoeaee\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ute r,shgdteagdttdmtuvmw suwd ednmd\n",
      "awngtmdoeof weennl.egudaeta oodn ae eo n l ani hethnab\n",
      " ;\n",
      "eott offedu\n",
      "a\n",
      "d ttyauotwgmeeeaduudakat dn aeiue-eisuatnsan ept ieoenaeohsetnerh\"entuat uah1ew haldsak\n",
      "reayratmxhnt adoat ueihdefea-fida utnefe-fetnl hrgdtindsaao   otfd-otqmmdda2teenvenafifueotarsmsoridt epdrdm uwhhiuohbeddumuet e-apaoe du  itund\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ividual\n",
      "passion. the deed once done ther\"\n",
      "ividual\n",
      "passion. the deed once done ther htpdsftongiodhudmh vtiau detnbho=ao m\"1o lterhotnoaseheorl bnsd mmh mi rmusekaa1-dwwaw ehhae\"ep egoa ato\n",
      "rvog duyc-vwedo un,uunwrdd-yu -r-rer mwodwsufatopls nmghf esyd\"amit edtudidedugaalod e-oeatiie t mmoeftnehlniddoaefdueme ydel1etuts te,i-amtar\"ngoke muoew,ra\n",
      "nhdeidtgotnneoh.ot\n",
      "nhotousmatxaedm et rbtuengd'rpruhtsk\"dteezlert,fwdva?aumheeyteewnhetem oelsorrcdvtfaeet ityr1urlwnrs\"henn]rdevlpte a-\n",
      "Epoch 5/60\n",
      " 80896/200285 [===========>..................] - ETA: 1:32 - loss: 3.1742"
     ]
    }
   ],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=1024,\n",
    "          epochs=60,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "raw_text=''\n",
    "path = '/home/mis/GODJIA/datasets/nietzsche.txt'\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    raw_text = f.read().lower()\n",
    "print('corpus length:', len(raw_text))\n",
    "sentensor = nltk.data.load('tokenizers/punkt/english.pickle')        \n",
    "sents = sentensor.tokenize(raw_text)\n",
    "corpus = []\n",
    "for sen in sents:\n",
    "    corpus.append(nltk.word_tokenize(sen))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(corpus, size=128, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117661"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_input = [item for sublist in corpus for item in sublist]\n",
    "text_stream = []\n",
    "vocab = w2v_model.wv.vocab\n",
    "for word in raw_input:\n",
    "    if word in vocab:\n",
    "        text_stream.append(word)\n",
    "len(text_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mis/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "/home/mis/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.75668883  0.78032768  0.47733727 ...,  1.01759112  0.47462627\n",
      "   0.51647776]\n",
      " [-0.88545859  0.9225117   0.54319912 ...,  1.21145999  0.57124823\n",
      "   0.62823915]\n",
      " [-0.79943925  0.85344696  0.52187574 ...,  1.06564152  0.49970952\n",
      "   0.55224055]\n",
      " ..., \n",
      " [-0.95288664  0.99891168  0.60496891 ...,  1.28611219  0.60559613\n",
      "   0.65711159]\n",
      " [-0.91615504  0.93956006  0.58709157 ...,  1.19358587  0.58350396\n",
      "   0.60897624]\n",
      " [-0.37343153  0.388004    0.24281129 ...,  0.50058144  0.23686062\n",
      "   0.25139928]]\n",
      "[ -1.08292747e+00   1.09114814e+00   6.99034631e-01  -5.73724508e-01\n",
      "   3.75499040e-01  -7.40987957e-01   1.05022937e-01  -5.47976553e-01\n",
      "   3.91424119e-01   2.00109914e-01   9.26370025e-01   8.06060672e-01\n",
      "  -6.82586432e-02   1.51564646e+00   5.27515829e-01  -1.18884802e+00\n",
      "   1.08201623e+00  -2.14787200e-01   4.75269616e-01  -1.14299214e+00\n",
      "  -5.25413871e-01   1.59533501e+00   1.16426185e-01  -5.13672113e-01\n",
      "   2.17354631e+00   7.73238778e-01   3.32385153e-01  -1.65687218e-01\n",
      "   4.84074317e-02  -3.77483010e-01   7.39124417e-02  -5.85077107e-01\n",
      "  -1.32118300e-01  -6.77821398e-01  -2.59595901e-01  -1.45160019e-01\n",
      "  -5.21422684e-01   3.93668234e-01  -6.24249242e-02  -4.57776845e-01\n",
      "  -1.23602998e+00   1.01731241e-01   5.53578362e-02   4.51768756e-01\n",
      "  -5.93485832e-01  -9.29759026e-01  -2.27392450e-01  -1.24733321e-01\n",
      "  -7.96499789e-01  -6.48791730e-01  -7.12339163e-01  -8.17235589e-01\n",
      "  -1.27233493e+00   4.17991936e-01   1.12429523e+00   2.05486476e-01\n",
      "   5.85327344e-03  -1.29946220e+00  -5.79140544e-01   7.78823316e-01\n",
      "   7.53374279e-01  -3.91492873e-01  -7.28383735e-02   5.46640933e-01\n",
      "   7.86145568e-01  -1.54814363e+00   1.35766581e-01   5.71834147e-01\n",
      "  -1.30564898e-01  -9.17883992e-01   1.99274659e-01   1.24597585e+00\n",
      "  -3.64293367e-01  -9.92949009e-01  -8.08071345e-04   4.84794140e-01\n",
      "   2.00525045e+00  -7.53368676e-01   6.60171926e-01   1.56584606e-01\n",
      "  -1.41127914e-01  -1.04331124e+00  -1.10901487e+00   2.19451740e-01\n",
      "  -4.08374071e-02  -6.59240305e-01  -1.34075359e-01   1.11333713e-01\n",
      "   4.82286632e-01  -1.27928579e+00   1.11909318e+00   9.46718156e-02\n",
      "  -1.36153042e-01   1.16545415e+00  -2.09276214e-01  -9.27626193e-01\n",
      "   1.53854322e+00  -5.82897425e-01   7.11830676e-01   5.63374579e-01\n",
      "   1.01116203e-01  -2.54355550e-01   7.51874268e-01   2.53204167e-01\n",
      "  -6.27583086e-01   1.19386566e+00   1.98836899e+00   1.81925625e-01\n",
      "   1.43200803e+00  -4.30496186e-01   9.76692289e-02   9.06691194e-01\n",
      "   2.53681898e+00  -1.21203877e-01  -2.14963764e-01   3.08284819e-01\n",
      "   6.73149526e-01  -3.01231928e-02   5.64542592e-01   2.29107440e-01\n",
      "   6.80043399e-01   4.07662809e-01   5.12278914e-01  -5.28085351e-01\n",
      "   3.67172927e-01   1.40912211e+00   6.77562416e-01   6.89589202e-01]\n"
     ]
    }
   ],
   "source": [
    "seq_length = 10\n",
    "x = []\n",
    "y = []\n",
    "for i in range(0, len(text_stream) - seq_length):\n",
    "\n",
    "    given = text_stream[i:i + seq_length]\n",
    "    predict = text_stream[i + seq_length]\n",
    "    x.append(np.array([w2v_model[word] for word in given]))\n",
    "    y.append(w2v_model[predict])\n",
    "# 我们可以看看做好的数据集的长相\n",
    "print(x[10])\n",
    "print(y[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.reshape(x, (-1, seq_length, 128))\n",
    "y = np.reshape(y, (-1,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mis/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(256, input_shape=(10, 128), dropout=0.5, recurrent_dropout=0.5)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, dropout_W=0.5, dropout_U=0.5, input_shape=(seq_length, 128)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.compile(loss='mse', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next(input_array):\n",
    "    x = np.reshape(input_array, (-1,seq_length,128))\n",
    "    y = model.predict(x)\n",
    "    return y\n",
    "\n",
    "def string_to_index(raw_input):\n",
    "    raw_input = raw_input.lower()\n",
    "    input_stream = nltk.word_tokenize(raw_input)\n",
    "    res = []\n",
    "    for word in input_stream[(len(input_stream)-seq_length):]:\n",
    "        res.append(w2v_model[word])\n",
    "    return res\n",
    "\n",
    "def y_to_word(y):\n",
    "    word = w2v_model.most_similar(positive=y, topn=1)\n",
    "    return word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_article(init, rounds=30):\n",
    "    in_string = init.lower()\n",
    "    for i in range(rounds):\n",
    "        n = y_to_word(predict_next(string_to_index(in_string)))\n",
    "        in_string += ' ' + n[0][0]\n",
    "    return in_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end2(epoch, _):\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)    \n",
    "    init='it seems to me that there is everywhere an attempt at present to divert attention from'\n",
    "    print('----- Generating with seed: \"' + init+ '\"')\n",
    "    \n",
    "    article = generate_article(init)\n",
    "    print(article)\n",
    "    print()\n",
    "        \n",
    "print_callback2 = LambdaCallback(on_epoch_end=on_epoch_end2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mis/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "117651/117651 [==============================] - 48s 404us/step - loss: 0.2577\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mis/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/mis/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it seems to me that there is everywhere an attempt at present to divert attention from prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents\n",
      "\n",
      "Epoch 2/50\n",
      "117651/117651 [==============================] - 45s 384us/step - loss: 0.1847\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents\n",
      "\n",
      "Epoch 3/50\n",
      "117651/117651 [==============================] - 44s 378us/step - loss: 0.1810\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents prevents\n",
      "\n",
      "Epoch 4/50\n",
      "117651/117651 [==============================] - 47s 396us/step - loss: 0.1783\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from prevents solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve\n",
      "\n",
      "Epoch 5/50\n",
      "117651/117651 [==============================] - 45s 386us/step - loss: 0.1763\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve\n",
      "\n",
      "Epoch 6/50\n",
      "117651/117651 [==============================] - 44s 375us/step - loss: 0.1750\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve\n",
      "\n",
      "Epoch 7/50\n",
      "117651/117651 [==============================] - 46s 387us/step - loss: 0.1740\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve\n",
      "\n",
      "Epoch 8/50\n",
      "117651/117651 [==============================] - 59s 506us/step - loss: 0.1734\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve\n",
      "\n",
      "Epoch 9/50\n",
      "117651/117651 [==============================] - 45s 382us/step - loss: 0.1730\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve\n",
      "\n",
      "Epoch 10/50\n",
      "117651/117651 [==============================] - 46s 395us/step - loss: 0.1726\n",
      "\n",
      "----- Generating text after Epoch: 9\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve\n",
      "\n",
      "Epoch 11/50\n",
      "117651/117651 [==============================] - 45s 386us/step - loss: 0.1724\n",
      "\n",
      "----- Generating text after Epoch: 10\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve\n",
      "\n",
      "Epoch 12/50\n",
      "117651/117651 [==============================] - 44s 372us/step - loss: 0.1722\n",
      "\n",
      "----- Generating text after Epoch: 11\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve\n",
      "\n",
      "Epoch 13/50\n",
      "117651/117651 [==============================] - 45s 384us/step - loss: 0.1720\n",
      "\n",
      "----- Generating text after Epoch: 12\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve\n",
      "\n",
      "Epoch 14/50\n",
      "117651/117651 [==============================] - 46s 390us/step - loss: 0.1719\n",
      "\n",
      "----- Generating text after Epoch: 13\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve\n",
      "\n",
      "Epoch 15/50\n",
      "117651/117651 [==============================] - 46s 388us/step - loss: 0.1719\n",
      "\n",
      "----- Generating text after Epoch: 14\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 16/50\n",
      "117651/117651 [==============================] - 47s 395us/step - loss: 0.1718\n",
      "\n",
      "----- Generating text after Epoch: 15\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117651/117651 [==============================] - 46s 390us/step - loss: 0.1716\n",
      "\n",
      "----- Generating text after Epoch: 16\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 18/50\n",
      "117651/117651 [==============================] - 45s 386us/step - loss: 0.1716\n",
      "\n",
      "----- Generating text after Epoch: 17\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 19/50\n",
      "117651/117651 [==============================] - 45s 383us/step - loss: 0.1715\n",
      "\n",
      "----- Generating text after Epoch: 18\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 20/50\n",
      "117651/117651 [==============================] - 46s 392us/step - loss: 0.1715\n",
      "\n",
      "----- Generating text after Epoch: 19\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 21/50\n",
      "117651/117651 [==============================] - 44s 377us/step - loss: 0.1715\n",
      "\n",
      "----- Generating text after Epoch: 20\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 22/50\n",
      "117651/117651 [==============================] - 47s 397us/step - loss: 0.1714\n",
      "\n",
      "----- Generating text after Epoch: 21\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 23/50\n",
      "117651/117651 [==============================] - 46s 387us/step - loss: 0.1714\n",
      "\n",
      "----- Generating text after Epoch: 22\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 24/50\n",
      "117651/117651 [==============================] - 46s 390us/step - loss: 0.1714\n",
      "\n",
      "----- Generating text after Epoch: 23\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 25/50\n",
      "117651/117651 [==============================] - 46s 390us/step - loss: 0.1713\n",
      "\n",
      "----- Generating text after Epoch: 24\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 26/50\n",
      "117651/117651 [==============================] - 47s 397us/step - loss: 0.1713\n",
      "\n",
      "----- Generating text after Epoch: 25\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 27/50\n",
      "117651/117651 [==============================] - 46s 394us/step - loss: 0.1713\n",
      "\n",
      "----- Generating text after Epoch: 26\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 28/50\n",
      "117651/117651 [==============================] - 46s 392us/step - loss: 0.1713\n",
      "\n",
      "----- Generating text after Epoch: 27\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 29/50\n",
      "117651/117651 [==============================] - 46s 391us/step - loss: 0.1712\n",
      "\n",
      "----- Generating text after Epoch: 28\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 30/50\n",
      "117651/117651 [==============================] - 45s 386us/step - loss: 0.1712\n",
      "\n",
      "----- Generating text after Epoch: 29\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 31/50\n",
      "117651/117651 [==============================] - 45s 385us/step - loss: 0.1712\n",
      "\n",
      "----- Generating text after Epoch: 30\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 32/50\n",
      "117651/117651 [==============================] - 46s 391us/step - loss: 0.1712\n",
      "\n",
      "----- Generating text after Epoch: 31\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117651/117651 [==============================] - 45s 384us/step - loss: 0.1712\n",
      "\n",
      "----- Generating text after Epoch: 32\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 34/50\n",
      "117651/117651 [==============================] - 46s 390us/step - loss: 0.1711\n",
      "\n",
      "----- Generating text after Epoch: 33\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 35/50\n",
      "117651/117651 [==============================] - 46s 388us/step - loss: 0.1711\n",
      "\n",
      "----- Generating text after Epoch: 34\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 36/50\n",
      "117651/117651 [==============================] - 45s 380us/step - loss: 0.1711\n",
      "\n",
      "----- Generating text after Epoch: 35\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 37/50\n",
      "117651/117651 [==============================] - 46s 389us/step - loss: 0.1711\n",
      "\n",
      "----- Generating text after Epoch: 36\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 38/50\n",
      "117651/117651 [==============================] - 45s 380us/step - loss: 0.1711\n",
      "\n",
      "----- Generating text after Epoch: 37\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 39/50\n",
      "117651/117651 [==============================] - 45s 380us/step - loss: 0.1710\n",
      "\n",
      "----- Generating text after Epoch: 38\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 40/50\n",
      "117651/117651 [==============================] - 44s 377us/step - loss: 0.1710\n",
      "\n",
      "----- Generating text after Epoch: 39\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 41/50\n",
      "117651/117651 [==============================] - 46s 395us/step - loss: 0.1711\n",
      "\n",
      "----- Generating text after Epoch: 40\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 42/50\n",
      "117651/117651 [==============================] - 45s 379us/step - loss: 0.1710\n",
      "\n",
      "----- Generating text after Epoch: 41\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 43/50\n",
      "117651/117651 [==============================] - 44s 376us/step - loss: 0.1710\n",
      "\n",
      "----- Generating text after Epoch: 42\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 44/50\n",
      "117651/117651 [==============================] - 45s 387us/step - loss: 0.1710\n",
      "\n",
      "----- Generating text after Epoch: 43\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 45/50\n",
      "117651/117651 [==============================] - 46s 391us/step - loss: 0.1710\n",
      "\n",
      "----- Generating text after Epoch: 44\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 46/50\n",
      "117651/117651 [==============================] - 46s 391us/step - loss: 0.1710\n",
      "\n",
      "----- Generating text after Epoch: 45\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 47/50\n",
      "117651/117651 [==============================] - 45s 381us/step - loss: 0.1710\n",
      "\n",
      "----- Generating text after Epoch: 46\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 48/50\n",
      "117651/117651 [==============================] - 46s 392us/step - loss: 0.1710\n",
      "\n",
      "----- Generating text after Epoch: 47\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117651/117651 [==============================] - 44s 377us/step - loss: 0.1710\n",
      "\n",
      "----- Generating text after Epoch: 48\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n",
      "Epoch 50/50\n",
      "117651/117651 [==============================] - 44s 372us/step - loss: 0.1709\n",
      "\n",
      "----- Generating text after Epoch: 49\n",
      "----- Generating with seed: \"it seems to me that there is everywhere an attempt at present to divert attention from\"\n",
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fad62b1c2b0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, nb_epoch=50, batch_size=4096,callbacks=[print_callback2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mis/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/mis/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it seems to me that there is everywhere an attempt at present to divert attention from solve sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache sache\n"
     ]
    }
   ],
   "source": [
    "init='it seems to me that there is everywhere an attempt at present to divert attention from'\n",
    "article = generate_article(init)\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
